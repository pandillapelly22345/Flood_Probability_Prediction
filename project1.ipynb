{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MonsoonIntensity                        0\n",
      "TopographyDrainage                      0\n",
      "RiverManagement                         0\n",
      "Deforestation                           0\n",
      "Urbanization                            0\n",
      "ClimateChange                           0\n",
      "DamsQuality                             0\n",
      "Siltation                               0\n",
      "AgriculturalPractices                   0\n",
      "Encroachments                           0\n",
      "IneffectiveDisasterPreparedness         0\n",
      "DrainageSystems                         0\n",
      "CoastalVulnerability                    0\n",
      "Landslides                              0\n",
      "Watersheds                              0\n",
      "DeterioratingInfrastructure             0\n",
      "PopulationScore                         0\n",
      "WetlandLoss                             0\n",
      "InadequatePlanning                      0\n",
      "PoliticalFactors                        0\n",
      "FloodProbability                   745305\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Load the data\n",
    "df = pd.read_csv('data_all.csv')\n",
    "\n",
    "# Select columns B to U as features and V as target\n",
    "feature_columns = df.columns[1:21]  # Columns B to U\n",
    "target_column = df.columns[21]  # Column V (FloodProbability)\n",
    "data = df[feature_columns.tolist() + [target_column]]\n",
    "\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "# Step 3: Display the missing values for each column\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = data.dropna()\n",
    "missing_values = df_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MonsoonIntensity                   0\n",
      "TopographyDrainage                 0\n",
      "RiverManagement                    0\n",
      "Deforestation                      0\n",
      "Urbanization                       0\n",
      "ClimateChange                      0\n",
      "DamsQuality                        0\n",
      "Siltation                          0\n",
      "AgriculturalPractices              0\n",
      "Encroachments                      0\n",
      "IneffectiveDisasterPreparedness    0\n",
      "DrainageSystems                    0\n",
      "CoastalVulnerability               0\n",
      "Landslides                         0\n",
      "Watersheds                         0\n",
      "DeterioratingInfrastructure        0\n",
      "PopulationScore                    0\n",
      "WetlandLoss                        0\n",
      "InadequatePlanning                 0\n",
      "PoliticalFactors                   0\n",
      "FloodProbability                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Last_column = 'FloodProbability'\n",
    "X = df_cleaned.drop(columns=[Last_column])\n",
    "y = df_cleaned[Last_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters:\n",
      "{'kernel': 'linear', 'C': 1}\n",
      "\n",
      "Training Set Metrics:\n",
      "Mean Squared Error: 0.0004\n",
      "Mean Absolute Error: 0.0164\n",
      "R-squared: 0.8396\n",
      "Root Mean Squared Error: 0.0204\n",
      "\n",
      "Test Set Metrics:\n",
      "Mean Squared Error: 0.0004\n",
      "Mean Absolute Error: 0.0164\n",
      "R-squared: 0.8395\n",
      "Root Mean Squared Error: 0.0204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def quick_svm_optimization(X, y):\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Quick parameter configurations to try\n",
    "    kernels = ['rbf', 'linear']\n",
    "    C_values = [0.1, 1, 10]\n",
    "    best_score = float('inf')\n",
    "    best_model = None\n",
    "    best_params = {}\n",
    "    \n",
    "    # Quick grid search\n",
    "    for kernel in kernels:\n",
    "        for C in C_values:\n",
    "            # Create and train SVR\n",
    "            svm_model = SVR(kernel=kernel, C=C)\n",
    "            svm_model.fit(X_train_scaled, y_train)\n",
    "            \n",
    "            # Predict and calculate MSE\n",
    "            y_pred = svm_model.predict(X_test_scaled)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            \n",
    "            # Track best model\n",
    "            if mse < best_score:\n",
    "                best_score = mse\n",
    "                best_model = svm_model\n",
    "                best_params = {'kernel': kernel, 'C': C}\n",
    "    \n",
    "    # Predictions with best model\n",
    "    y_pred_train = best_model.predict(X_train_scaled)\n",
    "    y_pred_test = best_model.predict(X_test_scaled)\n",
    "    \n",
    "    # Metrics\n",
    "    def print_metrics(y_true, y_pred, set_name):\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        print(f\"\\n{set_name} Set Metrics:\")\n",
    "        print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "        print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "        print(f\"R-squared: {r2:.4f}\")\n",
    "        print(f\"Root Mean Squared Error: {rmse:.4f}\")\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nBest Parameters:\")\n",
    "    print(best_params)\n",
    "    \n",
    "    print_metrics(y_train, y_pred_train, \"Training\")\n",
    "    print_metrics(y_test, y_pred_test, \"Test\")\n",
    "    \n",
    "    return best_model, best_params\n",
    "\n",
    "# Example usage\n",
    "model, best_params = quick_svm_optimization(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 6, 'min_samples_split': 15}\n",
      "\n",
      "Training Set Metrics:\n",
      "Mean Squared Error: 0.0013828548408835908\n",
      "Mean Absolute Error: 0.029825658764238264\n",
      "R-squared: 0.46910391462443746\n",
      "Root Mean Squared Error: 0.037186756256543683\n",
      "\n",
      "Testing Set Metrics:\n",
      "Mean Squared Error: 0.001813339369845602\n",
      "Mean Absolute Error: 0.03418918283148939\n",
      "R-squared: 0.30236746551884397\n",
      "Root Mean Squared Error: 0.04258332267268023\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# scaler = StandardScaler()\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# param_grid = {\n",
    "#     'max_depth': [None, 5, 10, 15, 20, 25],\n",
    "#     'min_samples_split': [2, 5, 10, 15],\n",
    "#     'min_samples_leaf': [1, 2, 4, 6],\n",
    "#     'max_features': [None, 'sqrt', 'log2']  # Corrected values\n",
    "# }\n",
    "\n",
    "# # Create Decision Tree Regressor\n",
    "# dt_regressor = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# # Perform Grid Search with Cross-Validation\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=dt_regressor,\n",
    "#     param_grid=param_grid,\n",
    "#     cv=5,\n",
    "#     scoring='r2',\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# # Fit Grid Search\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Best model\n",
    "# best_dt = grid_search.best_estimator_\n",
    "\n",
    "# # Predictions\n",
    "# y_train_pred = best_dt.predict(X_train)\n",
    "# y_test_pred = best_dt.predict(X_test)\n",
    "\n",
    "# # Evaluation Metrics\n",
    "# print(\"Best Parameters:\", grid_search.best_params_)\n",
    "# print(\"\\nTraining Set Metrics:\")\n",
    "# print(\"Mean Squared Error:\", mean_squared_error(y_train, y_train_pred))\n",
    "# print(\"Mean Absolute Error:\", mean_absolute_error(y_train, y_train_pred))\n",
    "# print(\"R-squared:\", r2_score(y_train, y_train_pred))\n",
    "# print(\"Root Mean Squared Error:\", np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "\n",
    "# print(\"\\nTesting Set Metrics:\")\n",
    "# print(\"Mean Squared Error:\", mean_squared_error(y_test, y_test_pred))\n",
    "# print(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_test_pred))\n",
    "# print(\"R-squared:\", r2_score(y_test, y_test_pred))\n",
    "# print(\"Root Mean Squared Error:\", np.sqrt(mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "scaler = StandardScaler()\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Test Set Metrics: R2: 0.6270, RMSE: 0.0311, MAE: 0.0255\n",
      "Train Set Metrics: R2: 0.8569, RMSE: 0.0193, MAE: 0.0159\n",
      "------------------------------------------------------------\n",
      "Testing parameters: {'n_estimators': 300, 'max_depth': 25, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt'}\n",
      "Test Set Metrics: R2: 0.6214, RMSE: 0.0314, MAE: 0.0257\n",
      "Train Set Metrics: R2: 0.8089, RMSE: 0.0223, MAE: 0.0181\n",
      "------------------------------------------------------------\n",
      "Testing parameters: {'n_estimators': 500, 'max_depth': None, 'min_samples_split': 15, 'min_samples_leaf': 6, 'max_features': 'log2'}\n",
      "Test Set Metrics: R2: 0.6067, RMSE: 0.0320, MAE: 0.0262\n",
      "Train Set Metrics: R2: 0.7562, RMSE: 0.0252, MAE: 0.0205\n",
      "------------------------------------------------------------\n",
      "Testing parameters: {'n_estimators': 1000, 'max_depth': 15, 'min_samples_split': 20, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Test Set Metrics: R2: 0.5614, RMSE: 0.0338, MAE: 0.0276\n",
      "Train Set Metrics: R2: 0.6773, RMSE: 0.0290, MAE: 0.0237\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# List of parameter sets to try\n",
    "param_trials = [\n",
    "    {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'},\n",
    "    {'n_estimators': 300, 'max_depth': 25, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt'},\n",
    "    {'n_estimators': 500, 'max_depth': None, 'min_samples_split': 15, 'min_samples_leaf': 6, 'max_features': 'log2'},\n",
    "    {'n_estimators': 1000, 'max_depth': 15, 'min_samples_split': 20, 'min_samples_leaf': 10, 'max_features': None},\n",
    "]\n",
    "\n",
    "# Iterate through each trial\n",
    "for trial in param_trials:\n",
    "    print(f\"Testing parameters: {trial}\")\n",
    "    \n",
    "    # Create the model with the current parameters\n",
    "    RF_model = RandomForestRegressor(\n",
    "        n_estimators=trial['n_estimators'],\n",
    "        max_depth=trial['max_depth'],\n",
    "        min_samples_split=trial['min_samples_split'],\n",
    "        min_samples_leaf=trial['min_samples_leaf'],\n",
    "        max_features=trial['max_features'],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    RF_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions on test and train sets\n",
    "    y_pred_test = RF_model.predict(X_test)\n",
    "    y_pred_train = RF_model.predict(X_train)\n",
    "    \n",
    "    # Calculate metrics for the test set\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "    \n",
    "    # Calculate metrics for the train set\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    rmse_train = np.sqrt(mse_train)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Test Set Metrics: R2: {r2_test:.4f}, RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}\")\n",
    "    print(f\"Train Set Metrics: R2: {r2_train:.4f}, RMSE: {rmse_train:.4f}, MAE: {mae_train:.4f}\")\n",
    "    print(\"-\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
